{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "NRelGV63egfO",
        "outputId": "b5d0d28d-ef9b-4709-d055-7c57e913aa70"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 13\n",
        "input_shape = (1, 28, 28)\n",
        "\n",
        "def load_images_from_folder(folder,index):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename),cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (28, 28))\n",
        "        if img is not None:\n",
        "            images.append([np.array(img), np.array(index)])\n",
        "    return images\n",
        "\n",
        "\n",
        "images = []\n",
        "for index,folder in enumerate(os.listdir(\"1.data cleaning\")):\n",
        "    images.extend(load_images_from_folder(\"1.data cleaning/\"+folder,index))\n",
        "\n",
        "X = np.array([i[0] for i in images]).reshape(-1, 28, 28, 1)\n",
        "Y = [i[1] for i in images]\n",
        "\n",
        "x_train= X.reshape(X.shape[0], 1, 28, 28).astype('float32')\n",
        "print(x_train.shape)\n",
        "y_train = np_utils.to_categorical(Y)\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "# x_train = np.expand_dims(x_train, -1)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 1000\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "print(\"XSHAPE - \")\n",
        "print(X.shape[0])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print(\"Test loss:\", score[0])\n",
        "# print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8ccb14e36db1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1.data cleaning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1.data cleaning/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1.data cleaning'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMBa62hhjdis",
        "outputId": "25af5f15-8e36-425c-fb03-3d78b282cdd0"
      },
      "source": [
        "# input_shape = (1, 28, 28)\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "img_path = \"/content/1.data cleaning/34_sleeve/full_0_1901000045.jpg\"\n",
        "img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
        "img = cv2.resize(img, (28, 28))\n",
        "# img_batch = np.expand_dims(img_array, axis=0)\n",
        "img = np.array(img).reshape(-1, 1, 28, 28)\n",
        "# img_preprocessed = preprocess_input(img_batch)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.3726800e-07 1.0891781e-05 6.5799384e-07 9.6160147e-06 3.0175243e-05\n",
            "  9.9871671e-01 9.6233680e-07 9.3815202e-04 2.1547501e-04 7.6993041e-05\n",
            "  1.2150821e-07 3.2402911e-10 2.6304254e-11]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}